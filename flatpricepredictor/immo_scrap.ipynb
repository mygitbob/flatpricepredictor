{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91e81e03-b3e8-490f-8437-d0589f683f1c",
   "metadata": {},
   "source": [
    "### Webscraper zum Erfassen der Berliner Immobiliendaten\n",
    "\n",
    "[Immobilienrechner - Main](./immo_main.ipynb)<br>\n",
    "[Immobilienrechner - Explorative Datenanalyse](./immo_eda.ipynb)<br>\n",
    "[Immobilienrechner - Modellentwicklung](./immo_model.ipynb)<br>\n",
    "[Immobilienrechner - Bereitstellung des besten Preisvorhersagemodells per Webinterface](./flask/immo_flask.ipynb)<br><br>\n",
    "Das Einlesen der Daten erfolgt via Selenium mit Hilfe von Firefox.\n",
    "\n",
    "Aufgrund rechtlicher Bestimmungen wurde die Url, welche durchsucht wird,\n",
    "aus dem Quellcode entfernt und durch eine manuelle Eingabe ersetzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8202c5b1-7997-443c-86d8-73f5ddf97e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import validators\n",
    "import shutil\n",
    "from random import randint\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from urllib.parse import urlparse\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c4ae26-cc8e-477d-9d91-6c0a58569940",
   "metadata": {},
   "source": [
    "#### Manuelle Url-Eingabe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9f6daa8-f206-42a6-93c6-76007bc937e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Zu \"scrapende\" Url eingeben (inklusive Protokoll): https://www.ebay-kleinanzeigen.de/s-wohnung-kaufen/berlin/seite:1/c196l3331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Url2scrap: https://www.ebay-kleinanzeigen.de/s-wohnung-kaufen/berlin/seite:1/c196l3331\n",
      "Base Url: https://www.ebay-kleinanzeigen.de\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    my_url = input('Zu \"scrapende\" Url eingeben (inklusive Protokoll):')\n",
    "    if validators.url(my_url):\n",
    "        break\n",
    "parsed = urlparse(my_url)\n",
    "base_url = parsed.scheme + '://' + parsed.netloc\n",
    "print('Url2scrap:', my_url)\n",
    "print('Base Url:', base_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d8d33a-5d90-44de-8311-f14a9d2b3662",
   "metadata": {},
   "source": [
    "#### Webscrap-Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241a05bd-61fe-48de-8281-9b3a2bba5828",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "max_visits = 1000\n",
    "driver = webdriver.Firefox()\n",
    "nan_count = 0\n",
    "previous_found = 0\n",
    "\n",
    "for page_nr in range(1, max_visits+1) :\n",
    "    \n",
    "    print('Lade Seite:', page_nr, my_url)\n",
    "    sleep(randint(5,8))\n",
    "    driver.get(my_url)\n",
    "    \n",
    "    li_items = driver.find_elements(By.XPATH, '//li[contains(@class,\"ad-listitem lazyload-item\")]')\n",
    "\n",
    "    for item in li_items:\n",
    "\n",
    "        artikel_name = item.find_element(By.XPATH, './/article')\n",
    "        artikel_name = artikel_name.get_attribute('data-href').split('/')[2]\n",
    "\n",
    "        try:\n",
    "            plz_elm = item.find_element(By.XPATH, './/div[@class=\"aditem-main--top--left\"]')\n",
    "        except: \n",
    "            plz_elm = None\n",
    "        if plz_elm:\n",
    "            plz = plz_elm.text\n",
    "            if plz == '': \n",
    "                #print('-------------- Alternative Plz !!!')\n",
    "                htm_str = plz_elm.get_attribute('outerHTML')\n",
    "                plz = htm_str[htm_str.find('i>')+2:htm_str.rfind('<')].strip()\n",
    "        else:\n",
    "            print('Kein Tag fuer Plz gefunden')\n",
    "\n",
    "        try:\n",
    "            preis_elm = item.find_element(By.XPATH, './/p[contains(@class,\"price\")]')\n",
    "        except: \n",
    "            preis_elm = None\n",
    "        if preis_elm:\n",
    "            preis = preis_elm.text\n",
    "            if preis == '': \n",
    "                #print('-------------- Alternativer Preis !!!')\n",
    "                htm_str = preis_elm.get_attribute('outerHTML')\n",
    "                preis = htm_str[htm_str.find('>')+1:htm_str.rfind('<')].strip()\n",
    "        else:\n",
    "            print('Kein Tag fuer Preis gefunden')\n",
    "\n",
    "        try:\n",
    "            ende = item.find_element(By.XPATH, './/p[@class=\"text-module-end\"]')\n",
    "        except:\n",
    "            try:\n",
    "                ende = item.find_element(By.XPATH, \n",
    "                        './/div[@class=\"aditem-main--bottom\"]/p')\n",
    "            except:\n",
    "                ende = None\n",
    "\n",
    "        if ende:\n",
    "            spans = ende.find_elements(By.XPATH, './/span')\n",
    "            if len(spans) > 0:\n",
    "                groesse = spans[0].text\n",
    "                if len(spans) > 1:\n",
    "                    zimmer = spans[1].text\n",
    "                else:\n",
    "                    zimmer = 'Keine Zimmer gefunden'\n",
    "            else:\n",
    "                groesse = 'Keine Groessenangabe gefunden'\n",
    "                zimmer = 'Keine Zimmer gefunden'\n",
    "                htm = ende.get_attribute('innerHTML')\n",
    "                htm = ende.get_attribute('outerHTML')\n",
    "        else:\n",
    "            print('Kein Tag fuer Ende gefunden')\n",
    "\n",
    "        if groesse == '' and zimmer == '':\n",
    "            groesse = spans[0].get_attribute('innerHTML').strip()\n",
    "            zimmer = spans[1].get_attribute('innerHTML').strip()\n",
    "        \n",
    "        try:\n",
    "            link_elm = item.find_element(By.XPATH, './/a[@class=\"ellipsis\"]')\n",
    "        except: \n",
    "            link_elm = None\n",
    "        if link_elm:\n",
    "            link = link_elm.get_attribute('href')\n",
    "            if not link.startswith('http'):\n",
    "                link = 'https://www.ebay-kleinanzeigen.de' + link\n",
    "            if plz == '': \n",
    "                #print('-------------- Alternativer Link !!!')\n",
    "                pass\n",
    "        else:\n",
    "            print('kein tag fuer link gefunden')\n",
    "        #print('link:', link)\n",
    "        \n",
    "        # werte ausschneiden, pruefen und speichern\n",
    "        if len(plz.split()) > 1:\n",
    "            plz_new = plz.split()[0].strip()\n",
    "            stadtteil = plz.split()[1].strip()\n",
    "        else:\n",
    "            plz_new = plz.split()[0].strip()\n",
    "            stadtteil = np.nan\n",
    "            nan_count += 1\n",
    "        try:\n",
    "            plz_new = int(plz_new)\n",
    "        except:\n",
    "            plz_new = np.nan\n",
    "            nan_count += 1\n",
    "        try:\n",
    "            preis = int(preis.split()[0].strip().replace('.',''))\n",
    "        except: \n",
    "            preis = np.nan\n",
    "            nan_count += 1\n",
    "        try:\n",
    "            groesse = float(groesse.split()[0].strip().replace(',','.'))\n",
    "        except:\n",
    "            groesse = np.nan\n",
    "            nan_count += 1\n",
    "        try: \n",
    "            zimmer = float(zimmer.split()[0].strip().replace(',','.'))\n",
    "        except: \n",
    "            zimmer = np.nan\n",
    "            nan_count += 1\n",
    "        result.append((plz_new, stadtteil, preis, groesse, zimmer, artikel_name, link))\n",
    "    \n",
    "    if len(result) == previous_found:\n",
    "        print(f'FEHLER: Keine Ergebnisse auf Seite {my_url}')\n",
    "    previous_found = len(result) \n",
    "    print('gefunden:', len(result), 'nan:', nan_count)\n",
    "    \n",
    "    try:\n",
    "        next_url_elm = driver.find_element(By.XPATH, \n",
    "                            './/div[@class=\"pagination-nav\"]/a[@class=\"pagination-next\" and @title=\"Nächste\"]')\n",
    "    except: \n",
    "        next_url_elm = None\n",
    "    if next_url_elm:\n",
    "        next_url = next_url_elm.get_attribute('href')\n",
    "        if not next_url.startswith('http'):\n",
    "            print(next_url)\n",
    "            next_url = base_url + next_url\n",
    "            print(next_url)\n",
    "    else:\n",
    "        print('Kein Tag fuer den nächsten Link gefunden -> fertig')\n",
    "        break\n",
    "    print('Nächste Seite:', next_url)\n",
    "    my_url = next_url\n",
    "        \n",
    "driver.quit()\n",
    "print('Webscrap beendet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa094cb-958b-4acf-966b-b86e2859ca02",
   "metadata": {},
   "source": [
    "#### DataFrame erstellen und als csv Datei speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8408493e-3575-4d02-8239-db29506bb656",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result, columns=['plz', 'stadtteil', 'preis', 'groesse',\n",
    "                                'zimmer', 'a_name', 'link'])\n",
    "f_name = 'eka__'+str(page_nr)+'_pages_'+str(len(result))+'_rows_'+ \\\n",
    "          str(nan_count)+'_nans__'+datetime.today().strftime('%Y-%m-%d %H:%M:')+'.csv'\n",
    "df.to_csv(f_name, index=False)\n",
    "\n",
    "if os.path.is_file('eka.csv'):\n",
    "    if os.path.is_file('eka.csv.bak'): os.remove('eka.csv.bak')\n",
    "    shutil.copy('eka.csv', 'eka.csv.bak')\n",
    "shutil.copy(f_name, 'eka.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
